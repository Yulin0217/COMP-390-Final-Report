\documentclass[12pt]{article}
\usepackage{geometry}
\geometry{a4paper}
\usepackage[colorlinks, linkcolor=blue, citecolor=blue, urlcolor=blue]{hyperref}
\usepackage[automake]{glossaries-extra}
\usepackage{appendix}
\usepackage{graphicx} % Needed for including images
\usepackage{mdframed} % For creating framed boxes
\usepackage[backend=biber, style=ieee]{biblatex} % Adding biblatex with IEEE style

\addbibresource{Reference.bib} % Specify the bibliography file, here 'references.bib'


\makeglossaries % 初始化术语表系统

% 定义一些术语
 
\newglossaryentry{opencv}{
    name=OpenCV,
    description={OpenCV (Open Source Computer Vision Library) is a library of programming functions mainly for real-time computer vision. Originally developed by Intel, it was later supported by Willow Garage, then Itseez (which was later acquired by Intel). The library is cross-platform and licensed as free and open-source software under Apache License 2. Starting in 2011, OpenCV features GPU acceleration for real-time operations.\cite{qt}}
}

\newglossaryentry{QT}{
    name=Qt,
    description={Qt (pronounced "cute" or as an initialism) is cross-platform application development framework for creating graphical user interfaces as well as cross-platform applications that run on various software and hardware platforms such as Linux, Windows, macOS, Android or embedded systems with little or no change in the underlying codebase while still being a native application with native capabilities and speed.\cite{cv}}
}

\newglossaryentry{aruco}{
    name=Aruco Marker,
    description={ArUco markers are 2D binary-encoded fiducial patterns designed to be quickly located by computer vision systems. ArUco marker patterns are defined by a binary dictionary in OpenCV, and the various library functions return pattern IDs and pose information from scanned images.\cite{arucomarkers}}
}

\newglossaryentry{vtk}{
      name=VTK,
      description={The Visualization Toolkit (VTK) is an open-source, freely available software system for 3D computer graphics, modeling, image processing, volume rendering, scientific visualization, and 2D plotting. It supports a wide variety of visualization algorithms and advanced modeling techniques, and it takes advantage of both threaded and distributed memory parallel processing for speed and scalability, respectively.\cite{vtkBook}}
}

\newglossaryentry{alpha}{
      name=Alpha Blending,
      description={In computer graphics, alpha compositing or alpha blending is the process of combining one image with a background to create the appearance of partial or full transparency. It is often useful to render picture elements (pixels) in separate passes or layers and then combine the resulting 2D images into a single, final image called the composite. Compositing is used extensively in film when combining computer-rendered image elements with live footage. Alpha blending is also used in 2D computer graphics to put rasterized foreground elements over a background.\cite{Alpha}}
}

\newglossaryentry{aesl}{
      name=Adaptive Exponential Smoothing,
      description={Adaptive exponential smoothing models are designed to improve performance by letting the smoothing parameter vary according to the most recent forecasting accuracy. \cite{aes,aes2}}
}

\newglossaryentry{emal}{
      name=Exponential Moving Average,
      description={An exponential moving average (EMA) is a type of moving average (MA) that places a greater weight and significance on the most recent data points. The exponential moving average is also referred to as the exponentially weighted moving average. An exponentially weighted moving average reacts more significantly to recent price changes than a simple moving average simple moving average (SMA), which applies an equal weight to all observations in the period.\cite{InvestopediaEMA}}
}
% 定义一个缩写词
\newabbreviation{aes}{AES}{
      Adaptive Exponential Smoothing}

\newabbreviation{ema}{EMA}{
      Exponential Moving Average}


\begin{document}
\begin{titlepage}
      \centering

      \includegraphics[width=0.6\textwidth]{Liverpool.jpg} % Increased width
      \vspace*{1cm}

      \Large
      COMP390

      \large
      2023/24

      \vspace{0.5cm}
      \Huge
      \textbf{Computer Vision and AR for Endovascular Intervention}

      \vspace{1.5cm}


      % Framed box for student information
      \begin{mdframed}
            \normalsize % Smaller text size within the box
            \textbf{Student Name:} [Yulin Huang]\\[20pt] % Name on the same line, add vertical space
            \textbf{Student ID:} [201676465]\\[20pt] % ID on the same line, add vertical space
            \textbf{Supervisor Name:} [Anh Nguyen] % Supervisor on the same line
      \end{mdframed}

      \vspace{2cm} % Adjust space as necessary
      \Large
      \textbf{DEPARTMENT OF}\\
      \vspace{0.1cm} % Adjust line spacing
      \textbf{COMPUTER SCIENCE}

      \vspace{4cm} % Large space as required
      \large
      University of Liverpool\\
      Liverpool L69 3BX


\end{titlepage}
% Acknowledgements page
\newpage
\thispagestyle{empty} % Remove page number from the acknowledgements page
\begin{center}
      \Large \textbf{Acknowledgements}
\end{center}
\vspace{1cm}
\normalsize
%Here for the Acknowledgements

\newpage
\begin{titlepage}
      \centering


      \includegraphics[width=0.6\textwidth]{Liverpool.jpg} % Increased width
      \vspace*{1cm}

      \Large
      COMP390
      \large
      2023/24

      \vspace{4.5cm}
      \Huge
      \textbf{Computer Vision and AR for Endovascular Intervention}

      \vspace{1.5cm}



      \vspace{4cm} % Adjust space as necessary
      \Large
      \textbf{DEPARTMENT OF}\\
      \vspace{0.1cm} % Adjust line spacing
      \textbf{COMPUTER SCIENCE}

      \vspace{1cm} % Large space as required
      \large
      University of Liverpool\\
      Liverpool L69 3BX

\end{titlepage}
\tableofcontents
\newpage

% Abstract 
\section*{Abstract}
This section should contain a concise summary of the document content.
% Statement of Ethical Compliance
\section*{Statement of Ethical Compliance}
\begin{mdframed}
      \Large % Larger font size for the first two lines
      Data Category: A \\
      Participant Category: 0 \\
      \normalsize % Normal font size for the rest of the text
      I confirm that I have read the ethical guidelines and will follow them during this project. Further details can be found in the relevant sections of this proposal.
\end{mdframed}
\newpage

% Introduction & Background
\section{Introduction \& Background}



\section{Design \& Implementation}

\subsection{Part1: Real-world Model Interaction and Tracking}
% 这一部分集中讨论与现实世界模型的交互与跟踪的设计和实现。

In this part, I used \gls{opencv}\cite{opencv_library} and SciKit-Surgery Augmented Reality\cite{Thompson_SciKit-Surgery_Compact_Libraries_2020} libraries for image
processing and  model tracking, while \gls{QT}\cite{QtWebsite} is used to design the graphical interface, and also \gls{vtk}\cite{vtkBook}. OpenCV and SciKit-Surgery help in processing images
and tracking \gls{aruco}\cite{1467495} within these images. Qt allows me to create a user-friendly interface that ensures multiple settings can be made more easily, enhancing the user experience.
VTK facilitates the management of overlay and multi-layer video rendering in my project.
An ArUco Marker Generator is also included, which enables the user to generate different ArUco Markers and save them.
This section will detail the system's design, focusing on System Components and Organization, Data Structures and Algorithms,
User Interface Design, and Design Notation and Diagrams.


\subsubsection{Design}
\begin{enumerate}
      \item \textbf{System Components and Organization}
            \\The project is structured into three primary components, each responsible for distinct functionalities within the system.
            Here’s a detailed breakdown of these components and their organization:
            \begin{enumerate}
                  \item \textbf{Frontend - User Interface}
                        \\The system's user interface is developed using Qt, a framework that enables the creation of graphically applications.
                        The main class controlling the UI is \emph{Overlay\_and\_Tracking.py}, which serves as the central hub for user interactions and display functionalities.
                        This class manages the overlay of models on video streams and provides interactive elements for users to control various settings, such as model color changes,
                        video source switching, models uploading and changing, or adjusting ArUco marker types and sizes, and more.
                  \item \textbf{Backend - Helper Classes}
                        \\The backend is composed of various helper classes, each set to handle specific tasks:
                        \begin{itemize}
                              \item \textit{Image Capture:} The \emph{video\_source.py} class handles the acquisition of video streams from various sources,
                                    including live cameras and recorded media. It is responsible for configuring camera settings, initializing video capture, and video frame cropping to adapted to screen size. This component ensures the reliability and stability of video feed intake.

                              \item \textit{Model Loading:} Managed by \emph{model\_loader.py}, this component is important for the model loading and initializing. It loads ".stl" model files from external files, sets up texture mapping, and prepares the models for real-time overlay. The class also checks for errors in model data to prevent crashes or rendering issues during operation. It also optimizes the structures of model data to enhance rendering efficiency and reduce memory overhead.

                              \item \textit{Model Overlay:} The \emph{overlay\_window.py} is central to integrating 3D models with live or recorded video. With the help of VTK, this module could set up a multi-layered rendering environment where each layer can independently handle elements like video backgrounds, 3D models, or some GUI overlays(In the future, maybe.).

                              \item \textit{Transform Management:} The \emph{transform\_manager.py} class provides a method for managing 4x4 transformation matrices crucial for spatial adjustments of models in 3D space. It stores and retrieves transformations efficiently. And allow it for dynamic modifications of object orientations and positions.

                              \item \textit{ArUco Marker Tracking:} Functionality provided by \emph{arucotracker.py} includes detecting and decoding ArUco markers from the video stream using OpenCV. This module calculates position and orientation of detected marker, and handle the spatial position data for model tracking.
                        \end{itemize}


                  \item \textbf{Additional Component - ArUco Marker Generator}
                        \\An independent component in the system is the ArUco Marker Generator, managed by \emph{Aruco\_Generator.py}.
                        This tool allows users to select and visualize different ArUco markers. Users can also save these markers as separate image files.
            \end{enumerate}
            \paragraph{Organization:\\}
            The system’s architecture is designed to easy maintenance and scalability.
            The modular nature of the helper classes allows for isolated development and testing,
            which enhances the system's robustness and flexibility.
            This organization simplifies development and testing
            and enables the integration of additional functionalities in the future with minimal disruption to the existing system.

      \item \textbf{Data Structures and Algorithms}
            % 详细说明系统所使用的数据结构和算法。
            \begin{enumerate}
                  \item \textbf{Pre-processing for video capture and upload}
                  
                  \item \textbf{Feature Data Structures}
                        % 详细说明用于存储从视频中提取的特征（如ArUco标记的位置、角点检测等）的数据结构，可能涉及到空间哈希表或树结构（如KD树、四叉树）。

                  \item \textbf{Image Processing Algorithms in Multi-Layer Video Rendering}
                       % 描述如何存储和处理连续的图像帧，例如使用循环缓冲区或队列来管理实时视频帧。
                       \\ In a video rendering system, video frames need to be de-dynamically managed to create complex visual effects, such as models and real-time video overlays in this project. This also involved real-time adjustments to the \gls{alpha}\cite{Alpha} and video. A greyscale image with alpha blending of the RGBA stream was used to precisely control transparency and layering effects to enable the superimposition of a layer's frame (e.g. the model) onto the original frame\cite{9979846}. Ensuring overlay accuracy and visual fidelity is crucial for applications such as augmented reality\cite{SETTIMI2022104272}.
                       \\
                       In addition, it is necessary to update and align the video frames to the appropriate layers by adjusting the data range according to the size of the incoming video frames. This incorporation of real-time processing improves the continuity of the video image by preventing visual interruptions caused by frame misalignment\cite{Wang_2021}.
                       \\
                       I also introduced \gls{aesl} into the multi-layer video rendering system (\emph{Overlay\_and\_Tracking.py}). This enhances image processing, such as when processing video streams involving complex dynamic scenes\cite{7410724}. By dynamically adjusting its smoothing parameter (Alpha), \gls{aes} is able to more accurately adapt to changes in content within a video frame, such as lighting adjustments, scene switching, or object movement, and can reduce visual jitter and blurring due to rapid changes \cite{7410724}.
                       \\
                       Compared with the traditional \gls{emal}, the adaptive feature of \gls{aes} has a greater advantage. \gls{ema}, although fast in processing and low in computational cost, may not be able to adequately adapt its fixed smoothing parameters to real-time changes in the video content in the face of complex scene variations, thus affecting the final image quality\cite{aes,aes2,InvestopediaEMA}.
                       In a multilayer rendering system, combining \gls{aes} for real-time video transmission and dynamically adjusting the smoothing parameters according to the content differences between the previous and previous frames can maintain the continuity and naturalness of the visual effects, especially when dealing with moving objects and changing backgrounds. In addition, \gls{aes}'s also better handles scenes with large lighting variations, maintaining the balance of colors and shades of light and dark \cite{7298776}.


                  \item \textbf{Marker Detection and Tracking}
                        % 详述用于检测和追踪ArUco标记的算法，包括图像分割、模式识别和机器学习技术。

                  \item \textbf{Model Positioning and Rendering}
                        % 介绍如何将三维模型精确地放置在虚拟环境中，可能涉及计算几何和物体识别算法。

                  \item \textbf{Optimization Techniques}
                        % 如果涉及到性能瓶颈，可以介绍用于优化上述算法的技术，如多线程处理、GPU加速或使用更高效的算法（如快速傅里叶变换代替传统卷积）。

                  \item \textbf{Algorithm Efficiency and Complexity}
                        % 分析关键算法的时间和空间复杂度，讨论在不同操作环境（如不同硬件或软件平台）下的性能表现。
            \end{enumerate}


      \item \textbf{User Interface Design}
            \begin{enumerate}
                  \item \textbf{Screen Mockups, Sketches, and Screenshots}
                        % 包括界面设计的屏幕模拟图、草图和截图。

                  \item \textbf{OpenCV-Based Real-world Interaction Component}
                        % 描述该组件如何将模拟整合到AR/VR平台，以及实时视频捕捉与覆盖的技术细节。

                  \item \textbf{ArUco Marker Detection and Model Positioning}
                        % 讨论如何在视频帧中自动检测ArUco标记，并实现模型在虚拟环境中的精确定位。
            \end{enumerate}


      \item \textbf{Design Notation and Diagrams}
            \begin{enumerate}
                  \item \textbf{Use Case Diagrams}
                        % 描述用例图及其在设计中的应用。

                  \item \textbf{Interaction Diagrams and Class Diagrams}
                        % 介绍交互图和类图的设计和功能。

                  \item \textbf{Pseudocode and Data Flow Diagrams}
                        % 提供系统关键部分的伪代码及数据流图。
            \end{enumerate}
\end{enumerate}

\subsubsection{Implementation}
% 在这里描述 Part1: Real-world Model Interaction and Tracking 部分的具体实现细节。

\subsection{Part2: Endovascular Intervention Simulation}
% 在这里详细介绍关于“Endovascular Intervention Simulation”的设计和实现。

\subsubsection{Design}
% 描述“Endovascular Intervention Simulation”部分的设计细节。

\subsubsection{Implementation}
% 描述“Endovascular Intervention Simulation”部分的具体实现细节。


% Testing & Evaluation
\section{Testing \& Evaluation}

% Project Ethics
\section{Project Ethics}

% Conclusion & Future Work
\section{Conclusion \& Future Work}
\subsection{Conclusion}

\subsection{Future Work}

\section{BCS Criteria \& Self-Reflection}

\subsection{An Ability to Apply Practical and Analytical Skills}
% Describe how you applied practical and analytical skills gained during your degree programme to your project.

\subsection{Innovation and/or Creativity}
% Discuss any innovative or creative approaches employed in your project.

\subsection{Synthesis of Information, Ideas, and Practices}
% Explain how you synthesized information, ideas, and practices to provide a quality solution. Include an evaluation of that solution.

\subsection{Meeting a Real Need in a Wider Context}
% Reflect on how your project meets a real need in a wider context.

\subsection{An Ability to Self-Manage a Significant Piece of Work}
% Reflect on your ability to self-manage the significant piece of work that is your project.

\subsection{Critical Self-Evaluation of the Process}
% Provide a critical self-evaluation of the process involved in your project.


% References (The bibliography will be printed here)
\printbibliography
\printglossaries

\end{document}
